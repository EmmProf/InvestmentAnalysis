{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import multivariate_normal\n",
    "from statsmodels.nonparametric.kernel_density import KDEMultivariate\n",
    "\n",
    "DataDF  = pd.read_pickle('DataDF')\n",
    "# DataDF = pd.read_pickle('DataDFbigRight')\n",
    "# DataDF = DataDF.loc[DataDF.area != 0]\n",
    "# DataDF = DataDF.loc[DataDF.mask_filename != 'None']\n",
    "# DataDF = DataDF.rename(columns={'jumbo_id':'id','tc_label':'label','mask_filename':'file'})\n",
    "\n",
    "GroupID = DataDF.groupby('id')\n",
    "## hyper-parameters\n",
    "## note: all hyper-parameters are set based on intuition, vizualising the distributions, but it might be better to set them\n",
    "## depending on each camera...\n",
    "\n",
    "#we care about big clusters for TPs, to get conditional areas (cluster is not small location) 40,20 20,15\n",
    "r1 = 20\n",
    "m1 = 15\n",
    "#we care about small static FPs location cluster 2,5 3,8 4,10\n",
    "r0 = 3\n",
    "m0 = 8\n",
    "#if we are not in a small cluster either in noise or in other location cluster (e.g. road), then we can use location\n",
    "#to have conditional areas to use full location info\n",
    "r00 = 10\n",
    "#then we want to set kde weights for area TPs tend to have larger areas so larger \"h\" \n",
    "l1 = 100\n",
    "#FPs smaller areas so we can set a smaller \"h\"\n",
    "l0 = 6\n",
    "\n",
    "def Training(CamDat,maxTPrm=0.02):\n",
    "    if sum(CamDat.label == '-1') < 5: print('Not enough FPs, no need for filter')\n",
    "    else:\n",
    "        if sum(CamDat.label == '1') < 5: print('Not enough TPs, too risky to use filter')\n",
    "\n",
    "        else:\n",
    "            CamFPs = CamDat.groupby('label').get_group('-1')\n",
    "            CamTPs = CamDat.groupby('label').get_group('1')\n",
    "            n1 = len(CamTPs)\n",
    "            n0 = len(CamFPs)\n",
    "            Trainloc1 = CamTPs[['Centroidsx','Centroidsy']]\n",
    "            Trainloc0 = CamFPs[['Centroidsx','Centroidsy']]\n",
    "            TrainArea1 = CamTPs.area\n",
    "            TrainArea0 = CamFPs.area\n",
    "\n",
    "            db1 = DBSCAN(eps=r1,min_samples=m1).fit(Trainloc1)\n",
    "            db0 = DBSCAN(eps=r0,min_samples=m0).fit(Trainloc0)\n",
    "\n",
    "            #cluster labels and noise label\n",
    "            labelsVector1 = db1.labels_\n",
    "            labels1 = np.unique(labelsVector1)\n",
    "            labelsVector0 = db0.labels_\n",
    "            labels0 = np.unique(labelsVector0)\n",
    "\n",
    "            Distrik1 = []\n",
    "            for k in labels1:  \n",
    "                nk = sum(labelsVector1==k)\n",
    "                if nk <= 3: continue\n",
    "                ClusLoc = Trainloc1.loc[labelsVector1==k,]\n",
    "                ClusArea = TrainArea1.loc[labelsVector1==k,]\n",
    "                #This factor makes sure that the measure of proba are comparable (removes advantage because of h or size of cluster)\n",
    "                #Check kde wikipedia article or https://stat.ethz.ch/education/semesters/ss2011/CompStat/sk.pdf\n",
    "                Factor = 1/(nk*(l1*r1*r1))\n",
    "                #weights given to largest cluster, here not sure in which cluster we are\n",
    "                xk = [ClusLoc.Centroidsx.values,ClusLoc.Centroidsy.values,ClusArea.values]\n",
    "                Distrik1.append(KDEMultivariate(xk, bw=[r1,r1,l1],var_type='ccc'))\n",
    "\n",
    "            Distrik0 = []\n",
    "            for k in labels0:  \n",
    "                nk = sum(labelsVector0==k)\n",
    "                if nk <= 3: continue\n",
    "                ClusLoc = Trainloc0.loc[labelsVector0==k,]\n",
    "                ClusArea = TrainArea0.loc[labelsVector0==k,]\n",
    "                #This factor makes sure that the measure of proba are comparable (removes advantage because of h or size of cluster)\n",
    "                #Check kde wikipedia article or https://stat.ethz.ch/education/semesters/ss2011/CompStat/sk.pdf\n",
    "                Factor = 1/(nk*(l0*r0*r0))\n",
    "                if k == -1: Factor = 1/(nk*(l0*r00*r00))\n",
    "                #weights given to largest cluster, here not sure in which cluster we are\n",
    "                xk = [ClusLoc.Centroidsx.values,ClusLoc.Centroidsy.values,ClusArea.values]\n",
    "                Distrik0.append(KDEMultivariate(xk, bw=[r0,r0,l0],var_type='ccc'))\n",
    "\n",
    "            def LR(v):\n",
    "                p0 = max([p0.pdf(v) for p0 in Distrik0 if p0 is not None])\n",
    "                p1 = max([p1.pdf(v) for p1 in Distrik1 if p1 is not None])\n",
    "                if p0 == 0 or p1 == 0: return 0\n",
    "                else : return p0/p1\n",
    "\n",
    "            #find threshold likelihood with 3% max TP removed\n",
    "            ratio1 = []\n",
    "            for x,y,a in zip(Trainloc1.Centroidsx,Trainloc1.Centroidsy,TrainArea1):\n",
    "                r = LR([x,y,a])\n",
    "                ratio1.append(r)\n",
    "            ratio0 = []\n",
    "            for x,y,a in zip(Trainloc0.Centroidsx,Trainloc0.Centroidsy,TrainArea0):\n",
    "                r = LR([x,y,a])\n",
    "                ratio0.append(r)\n",
    "        \n",
    "            FPT = lambda T: sum( e > T for e in ratio1)/len(ratio1)\n",
    "            Ts = np.sort(np.array(ratio1))\n",
    "            FPsT = FPT(Ts)\n",
    "            if len(FPsT <= maxTPrm) == 0: T = Ts[-1]\n",
    "            else: T = Ts[FPsT <= maxTPrm][0]\n",
    "            print(T)\n",
    "\n",
    "            def C(v):\n",
    "                if (LR(v) > T) : return '-1'\n",
    "                else : return '1'\n",
    "\n",
    "        #THIS IS NOT USING A THRESHOLD BUT ANOTHER LIKELIHOODRATIO     \n",
    "#             dist1 = KDEMultivariate(ratio1,var_type='c')\n",
    "#             dist0 = KDEMultivariate(ratio0,var_type='c')\n",
    "\n",
    "#             def CC(v):\n",
    "#                 if (dist0.pdf([LR(v)])/dist1.pdf([LR(v)]) > 1) : return '-1'\n",
    "#                 else : return '1'\n",
    "\n",
    "            return C\n",
    "\n",
    "\n",
    "def getAreaThresholdF1(area,label,MaxFilteredOutTPs=0.05,ThresholdMax=45):\n",
    "    #MaxFilteredOutTPs should be in [0,1)\n",
    "    if not (0 <= MaxFilteredOutTPs < 1): \n",
    "        print('MaxFilteredOutTPs should be in [0,1)')\n",
    "        return 0\n",
    "\n",
    "    FP = [x for x, y in zip(area, label) if y == '-1']\n",
    "    TP = [x for x, y in zip(area, label) if y == '1']\n",
    "    n1 = len(TP)\n",
    "    n0 = len(FP)\n",
    "\n",
    "    Threshold = 0\n",
    "    #if there is no TPs for the camera, then the threshold is set to -1\n",
    "    if n1 == 0: \n",
    "        Threshold = -1\n",
    "    #else we maximize a F1 score over the thresholds that remove at most MaxFilteredOutTPs TPs\n",
    "    else :\n",
    "        F1ts = []\n",
    "        for t in range(ThresholdMax):\n",
    "            #how many TPs are not filtered out if the threshold is t (should be maximized)\n",
    "            n1t = len([e for e in TP if e > t])\n",
    "            Recallt = n1t/n1\n",
    "            #if too many TPs are filtered out, then the threshold is too high\n",
    "            if (Recallt < 1 - MaxFilteredOutTPs): break\n",
    "            #how many FPs are not filtered out if the threshold is t (should be minimized)\n",
    "            n0t = len([e for e in FP if e > t])\n",
    "            #n1t can not be 0 because Recallt => 1 - MaxFilteredOutTPs > 0\n",
    "            Precisiont = n1t/(n1t + n0t)\n",
    "            F1t = 2/(1/Precisiont + 1/Recallt)\n",
    "            F1ts.append(F1t)\n",
    "        #take the Threshold maximizing F1 score\n",
    "        #F1ts can not be empty because for t = 0, Recallt = 1, so the loop will always break after t = 0\n",
    "        Threshold = np.argmax(F1ts)\n",
    "        \n",
    "        #Depending on the number of TPs and the threshold value decide if the number of TPs is enough to set a filter\n",
    "        if n1 < 40 and Threshold > 5: Threshold = -5 #there should be more than 40 TPs if thresholds is more than 5\n",
    "        if n1 < 80 and Threshold > 15: Threshold = -15 #there should be more than 80 TPs if thresholds is more than 15\n",
    "        if n1 < 200 and Threshold > 25: Threshold = -25 #there should be more than 200 TPs if thresholds is more than 30\n",
    "\n",
    "    return Threshold\n",
    "\n",
    "def getInfos(group,T):\n",
    "\n",
    "    Ns = []\n",
    "\n",
    "    TPs = sum(group.groupby('label').get_group('1').area <= T)\n",
    "    FPs = sum(group.groupby('label').get_group('-1').area <= T)\n",
    "    TPso = len(group.groupby('label').get_group('1'))\n",
    "    FPso = len(group.groupby('label').get_group('-1'))\n",
    "    Ns = len(group)\n",
    "\n",
    "    Infos = dict()\n",
    "\n",
    "    Infos['#TPs removed'] = TPs\n",
    "    Infos['Total number of TPs'] = TPso\n",
    "    Infos['%TPs removed'] = np.round(TPs/TPso,2)\n",
    "    Infos['#FPs removed'] = FPs\n",
    "    Infos['Total number of FPs'] = FPso\n",
    "    Infos['%FPs removed'] = np.round(FPs/FPso,2)\n",
    "    Infos['Number of observation'] = Ns\n",
    "    \n",
    "    return Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Infos = []\n",
    "for n,g in GroupID:\n",
    "    if len(np.unique(g.label)) == 2:\n",
    "        Inf = getInfos(g,getAreaThresholdF1(g.area,g.label))\n",
    "        if Inf['#FPs removed'] >0 : Infos.append(Inf)\n",
    "\n",
    "GlobalFPsremoved = np.round(pd.DataFrame(Infos).loc[:,'#FPs removed'].sum()/pd.DataFrame(Infos).loc[:,\"Total number of FPs\"].sum(),2)\n",
    "\n",
    "GlobalTPsremoved = np.round(pd.DataFrame(Infos).loc[:,'#TPs removed'].sum()/pd.DataFrame(Infos).loc[:,\"Total number of TPs\"].sum(),2)\n",
    "\n",
    "MeanFPsremoved = np.round(pd.DataFrame(Infos).loc[:,'%FPs removed'].mean(),2)\n",
    "\n",
    "MeanTPsremoved = np.round(pd.DataFrame(Infos).loc[:,'%TPs removed'].mean(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaskPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-b2e41e2c94c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMaskUtil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaskPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MaskPath' is not defined"
     ]
    }
   ],
   "source": [
    "MaskUtil = cv2.imread(MaskPath,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectCam(ID):\n",
    "    FileName.options = GroupID.get_group(ID).file\n",
    "    FileName.value = GroupID.get_group(ID).file.iloc[0]\n",
    "    if len(np.unique(GroupID.get_group(ID).label)) !=1:\n",
    "        Threshold.value = getAreaThresholdF1(GroupID.get_group(ID).area,GroupID.get_group(ID).label)\n",
    "        Classifier = Training(GroupID.get_group(ID))\n",
    "    else: Threshold.value = 0\n",
    "def selectFile(File):\n",
    "    display(k)\n",
    "def f(T):\n",
    "    %matplotlib notebook\n",
    "#     print(T)\n",
    "#     plt.plot(DataDF.area.iloc[:300],DataDF.area.iloc[:300])\n",
    "#     plt.figure()\n",
    "#     plt.plot(DataDF.area.iloc[:300],DataDF.area.iloc[:300])\n",
    "    \n",
    "    ID = CamID.value\n",
    "    maskFile = FileName.value\n",
    "    timestamp = maskFile[18:38]\n",
    "#     rawFile = DataDFBig.raw_filename.loc[DataDFBig.mask_filename == maskFile].values[0]\n",
    "    rawFile = [e for e in os.listdir('raw/' + ID ) if timestamp in e][0]\n",
    "    MaskPath ='MasksOld/' + ID + '/' + maskFile\n",
    "    RoIPath = 'RoIs/' + ID + '.png'\n",
    "    rawPath ='raw/' + ID + '/' + rawFile\n",
    "    RoIPath = 'RoIs/' + ID + '.png'\n",
    "\n",
    "    #establish which connected components area removed\n",
    "    MaskUtil = cv2.imread(MaskPath,0)\n",
    "    RoIPath = 'RoIs/' + ID + '.png'\n",
    "    RoIUtil = cv2.imread(RoIPath,0)\n",
    "    MaskUtil[MaskUtil > 127] = 255\n",
    "    MaskUtil[MaskUtil <= 127] = 0\n",
    "       \n",
    "    Stats = cv2.connectedComponentsWithStats(MaskUtil)\n",
    "    MulticolMask = Stats[1]\n",
    "    if Stats[0] == 1: \n",
    "        print('There is no masks for ',file)\n",
    "    else:\n",
    "        SubMaskValue = MulticolMask[RoIUtil == 255]\n",
    "        for e in range(Stats[0] -1):\n",
    "            if len(SubMaskValue[SubMaskValue == e+1]) == 0:\n",
    "                MaskUtil[MulticolMask == e+1] = 0\n",
    "    \n",
    "    Stats = cv2.connectedComponentsWithStats(MaskUtil)\n",
    "    areas = Stats[2][1:,4]\n",
    "    labels = np.arange(1,len(areas)+1)[areas <= T] \n",
    "    labelsc = np.arange(1,len(areas)+1)[areas > T]\n",
    "    for e in labels:\n",
    "        Stats[1][Stats[1]==e] = 1\n",
    "    for e in labelsc:\n",
    "        Stats[1][Stats[1]==e] = 3\n",
    "    \n",
    "    #make a nice plot\n",
    "    Raw = cv2.imread(rawPath)\n",
    "    Mask = cv2.imread(MaskPath)\n",
    "    RoI = cv2.imread(RoIPath)\n",
    "\n",
    "    overlay = Raw.copy()\n",
    "    output = Raw.copy()\n",
    "\n",
    "    for i in range(len(overlay)):\n",
    "        for j in range(len(overlay[i])):\n",
    "            if RoI[i][j][1] == 255: overlay[i][j] = [255,255,0] \n",
    "\n",
    "    a = cv2.addWeighted(overlay, 0.2, output, 1 - 0.2,0, output)\n",
    "\n",
    "    overlay1 = output.copy()\n",
    "    output1 = output.copy()\n",
    "\n",
    "    for i in range(len(overlay1)):\n",
    "        for j in range(len(overlay1[i])):\n",
    "            if Stats[1][i][j] == 1: overlay1[i][j] = [255,0,0] \n",
    "            if Stats[1][i][j] == 3: overlay1[i][j] = [0,255,0] \n",
    "\n",
    "    b = cv2.addWeighted(overlay1, 0.4, output1, 1 - 0.4,0, output1)\n",
    "    if len(np.unique(GroupID.get_group(ID).label)) !=1:\n",
    "        display(getInfos(GroupID.get_group(ID),Threshold.value))\n",
    "    plt.close()\n",
    "    plt.imshow(output1)\n",
    "    plt.show()\n",
    "    title1 = int((GroupID.get_group(ID).loc[GroupID.get_group(ID).file == maskFile,'label'] == '-1'))*'False Positive' + int((GroupID.get_group(ID).loc[GroupID.get_group(ID).file == maskFile,'label'] == '1'))*'True Positive'\n",
    "\n",
    "#     overlay1 = output.copy()\n",
    "#     output1 = output.copy()\n",
    "    \n",
    "#     line = GroupID.get_group(ID).loc[GroupID.get_group(ID).file == maskFile,] \n",
    "#     x = line.Centroidsx.values[0]\n",
    "#     y = line.Centroidsy.values[0]\n",
    "#     a = line.area.values[0]\n",
    "#     col = [255,0,0]\n",
    "#     if Classifier([x,y,a]) == '1':\n",
    "#         col = [0,255,0] \n",
    "\n",
    "#     for i in range(len(overlay1)):\n",
    "#         for j in range(len(overlay1[i])):\n",
    "#             if MaskUtil[i][j] == 255: overlay1[i][j] = col\n",
    "\n",
    "\n",
    "#     b = cv2.addWeighted(overlay1, 0.4, output1, 1 - 0.4,0, output1) \n",
    "#     plt.imshow(output1)\n",
    "#     plt.title(title1)\n",
    "#     plt.show()\n",
    "\n",
    "def NextImage(b):\n",
    "    idx = FileName.options.index(FileName.value)\n",
    "    if idx != len(FileName.options)-1:\n",
    "        FileName.value = FileName.options[idx +1]\n",
    "def NextCamID(b):\n",
    "    idx = CamID.options.index(CamID.value)\n",
    "    if idx != len(CamID.options)-1:\n",
    "        CamID.value = CamID.options[idx +1]\n",
    "def PrevImage(b):\n",
    "    idx = FileName.options.index(FileName.value)\n",
    "    if idx != 0:\n",
    "        FileName.value = FileName.options[idx -1]\n",
    "def PrevCamID(b):\n",
    "    idx = CamID.options.index(CamID.value)\n",
    "    if idx != 0:\n",
    "        CamID.value = CamID.options[idx -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "layout = {'width':'500px'}\n",
    "CamID = widgets.Dropdown(options=np.unique(DataDF.id),style=style,layout=layout)\n",
    "init = GroupID.get_group(CamID.value).file\n",
    "FileName = widgets.Dropdown(options = init,style=style,layout=layout)\n",
    "Threshold = widgets.FloatSlider(min=0, max=200, step=1, description='Threshold:',style=style,\n",
    "                                layout=layout)\n",
    "buttonFileNext = widgets.Button(description=\"Next\",layout={'width':'50px'},style=style)\n",
    "buttonFileNext.on_click(NextImage)\n",
    "buttonCamNext = widgets.Button(description=\"Next\",layout={'width':'50px'})\n",
    "buttonCamNext.on_click(NextCamID)\n",
    "buttonFilePrev = widgets.Button(description=\"Prev\",layout={'width':'50px'})\n",
    "buttonFilePrev.on_click(PrevImage)\n",
    "buttonCamPrev = widgets.Button(description=\"Prev\",layout={'width':'50px'})\n",
    "buttonCamPrev.on_click(PrevCamID)\n",
    "\n",
    "i = widgets.interactive(selectCam,ID=CamID)\n",
    "j = widgets.interactive(selectFile,File= FileName)\n",
    "k = widgets.interactive(f,T = Threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ad7343fcc947bcb90dec82daa0157a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(Button(description='Prev', layout=Layout(width='50px'), style=ButtonStyle()), Button(description='Next', layout=Layout(width='50px'), style=ButtonStyle()), interactive(children=(Dropdown(description='ID', layout=Layout(width='500px'), options=('2514a72b-ead6-44a4-bafb-e4c8a684c599', '45dc97ec-7079-4525-8db4-aba80cef9c84', '563f9f49-aefa-4cf0-a0d5-bf6b5ac86ef8', 'ID-1C21D1C00131', 'ID-1C21D1C0013E', 'ID-1C21D1C0014E', 'ID-1C21D1C0015A', 'ID-1C21D1C00174', 'ID-1C21D1C00198', 'ID-1C21D1C001A0', 'ID-1C21D1C001A1', 'ID-1C21D1C001A2', 'ID-1C21D1C001A3', 'ID-1C21D1C001A4', 'ID-1C21D1C001A5', 'ID-1C21D1C001A6', 'ID-1C21D1C001A7', 'ID-1C21D1C001D0', 'ID-1C21D1C001E9', 'ID-1C21D1C00249', 'ID-1C21D1C0024D', 'ID-1C21D1C00262', 'ID-1C21D1C00265', 'ID-1C21D1C00266', 'ID-1C21D1C00267', 'ID-1C21D1C00278', 'ID-1C21D1C0027D', 'ID-1C21D1C0027E', 'ID-1C21D1C00281', 'ID-1C21D1C00287', 'ID-1C21D1C0028D', 'ID-1C21D1C002B0', 'ID-1C21D1C002B2', 'ID-1C21D1C002B4', 'ID-1C21D1C002C0', 'ID-1C21D1C002D0', 'ID-1C21D1C002D1', 'ID-1C21D1C002D2', 'ID-1C21D1C002D3', 'ID-1C21D1C002D4', 'ID-1C21D1C002E8', 'ID-1C21D1C002F9', 'ID-1C21D1C00312', 'ID-1C21D1C00313', 'ID-1C21D1C0032E', 'ID-1C21D1C00345', 'ID-1C21D1C003A1', 'ID-1C21D1C003C8', 'ID-1C21D1C003D9', 'ID-1C21D1C003DA', 'ID-1C21D1C003DC', 'ID-1C21D1C003E0', 'ID-1C21D1C003E4', 'ID-1C21D1C003E9', 'ID-1C21D1C003EA', 'ID-1C21D1C003EC', 'ID-1C21D1C003FB', 'ID-1C21D1C00436', 'ID-1C21D1C0044B', 'ID-1C21D1C004AC', 'ID-1C21D1C004B8', 'ID-1C21D1C004B9', 'ID-1C21D1C004BA', 'ID-1C21D1C004BB', 'ID-1C21D1C004BC', 'ID-1C21D1C004BD', 'ID-1C21D1C004C6', 'ID-1C21D1C004D7', 'ID-1C21D1C004DF', 'ID-1C21D1C004E9', 'ID-1C21D1C004EE', 'ID-1C21D1C004F0', 'ID-1C21D1C004F1', 'ID-1C21D1C004F3', 'ID-1C21D1C004F4', 'ID-1C21D1C004F6', 'ID-1C21D1C004F7', 'ID-1C21D1C00503', 'ID-1C21D1C00513', 'ID-1C21D1C00514', 'ID-1C21D1C00515', 'ID-1C21D1C00516', 'ID-1C21D1C00543', 'ID-1C21D1C0054A', 'ID-1C21D1C00599', 'ID-1C21D1C0059A', 'ID-1C21D1C005B4', 'ID-1C21D1C005C2', 'ID-1C21D1C005C3', 'ID-1C21D1C005C5', 'ID-1C21D1C005C6', 'ID-1C21D1C005C7', 'ID-1C21D1C00603', 'ID-1C21D1C00610', 'ID-1C21D1C006E2', 'ID-1C21D1C006E3', 'ID-1C21D1C00718', 'ID-1C21D1C00719', 'ID-1C21D1C0071A', 'ID-1C21D1C0071D', 'ID-1C21D1C00720', 'ID-1C21D1C00722', 'ID-1C21D1C00723', 'ID-1C21D1C00724', 'ID-1C21D1C007DA', 'ID-1C21D1C007E0', 'ID-1C21D1C007E1', 'ID-1C21D1C007E2', 'ID-1C21D1C007E3', 'ID-1C21D1C007E5', 'ID-1C21D1C0080F', 'ID-1C21D1C00819', 'ID-1C21D1C0090E', 'ID-1C21D1C0091C', 'ID-1C21D1C0092B', 'ID-1C21D1C00931', 'ID-1C21D1C0093A', 'ID-1C21D1C0093B', 'ID-1C21D1C0093C', 'ID-1C21D1C0093D', 'ID-1C21D1C0093E', 'ID-1C21D1C0093F', 'ID-1C21D1C00947', 'ID-1C21D1C0096A', 'ID-1C21D1C0096C', 'ID-1C21D1C009D9', 'ID-1C21D1C00A04', 'ID-1C21D1C00A06', 'ID-1C21D1C00A07', 'ID-1C21D1C00A0A', 'ID-1C21D1C00A0D', 'ID-1C21D1C00A0E', 'ID-1C21D1C00A0F', 'ID-1C21D1C00A10', 'ID-1C21D1C00A11', 'ID-1C21D1C00A13', 'ID-1C21D1C00A15', 'ID-1C21D1C00A16', 'ID-1C21D1C00A18', 'ID-1C21D1C00A19', 'ID-1C21D1C00A1A', 'ID-1C21D1C00A1B', 'ID-1C21D1C00A1C', 'ID-1C21D1C00A1D', 'ID-1C21D1C00A1E', 'ID-1C21D1C00A1F', 'ID-1C21D1C00A20', 'ID-1C21D1C00A21', 'ID-1C21D1C00A22', 'ID-1C21D1C00A23', 'ID-1C21D1C00A31', 'ID-1C21D1C00A35', 'ID-1C21D1C00A51', 'ID-1C21D1C00A53', 'ID-1C21D1C00A56', 'ID-1C21D1C00A57', 'ID-1C21D1C00A5A', 'ID-1C21D1C00A5B', 'ID-1C21D1C00A5E', 'ID-1C21D1C00A5F', 'ID-1C21D1C00A68', 'ID-1C21D1C00A6B', 'ID-1C21D1C00A6E', 'ID-1C21D1C00A74', 'ID-1C21D1C00A75', 'ID-1C21D1C00A76', 'ID-1C21D1C00A77', 'ID-1C21D1C00A78', 'ID-1C21D1C00A79', 'ID-1C21D1C00A7A', 'ID-1C21D1C00A7B', 'ID-1C21D1C00A7D', 'ID-1C21D1C00A7F', 'ID-1C21D1C00A89', 'ID-1C21D1C00A8C', 'ID-1C21D1C00A8E', 'ID-1C21D1C00A8F', 'ID-1C21D1C00A91', 'ID-1C21D1C00A92', 'ID-1C21D1C00A94', 'ID-1C21D1C00A95', 'ID-1C21D1C00A96', 'ID-1C21D1C00A97', 'ID-1C21D1C00A98', 'ID-1C21D1C00A99', 'ID-1C21D1C00A9A', 'ID-1C21D1C00A9B', 'ID-1C21D1C00AAC', 'ID-1C21D1C00AAD', 'ID-1C21D1C00AAF', 'ID-1C21D1C00AB1', 'ID-1C21D1C00AB3', 'ID-1C21D1C00AB5', 'ID-1C21D1C00AB7', 'ID-1C21D1C00ABC', 'ID-1C21D1C00AC8', 'ID-1C21D1C00ACA', 'ID-1C21D1C00ACB', 'ID-1C21D1C00ACC', 'ID-1C21D1C00ACE', 'ID-1C21D1C00AD0', 'ID-1C21D1C00ADC', 'ID-1C21D1C00ADF', 'ID-1C21D1C00AE0', 'ID-1C21D1C00AE1', 'ID-1C21D1C00AE2', 'ID-1C21D1C00AE3', 'ID-1C21D1C00AEC', 'ID-1C21D1C00AF6', 'ID-1C21D1C00AF7', 'ID-1C21D1C00AF8', 'ID-1C21D1C00AFF', 'ID-1C21D1C00B01', 'ID-1C21D1C00B02', 'ID-1C21D1C00B0F', 'ID-1C21D1C00B10', 'ID-1C21D1C00B11', 'ID-1C21D1C00B13', 'ID-1C21D1C00B14', 'ID-1C21D1C00B17', 'ID-1C21D1C00B18', 'ID-1C21D1C00B19', 'ID-1C21D1C00B1D', 'ID-1C21D1C00B1E', 'ID-1C21D1C00B1F', 'ID-1C21D1C00B20', 'ID-1C21D1C00B22', 'ID-1C21D1C00B23', 'ID-1C21D1C00B64', 'ID-1C21D1C00B67', 'ID-1C21D1C00B68', 'ID-1C21D1C00B69', 'ID-1C21D1C00B6A', 'ID-1C21D1C00B6B', 'ID-1C21D1C00B9E', 'ID-1C21D1C00B9F', 'ID-1C21D1C00BA0', 'ID-1C21D1C00BA1', 'ID-1C21D1C00BA2', 'ID-1C21D1C00BA3', 'ID-1C21D1C00BA4', 'ID-1C21D1C00BA8', 'ID-1C21D1C00BAA', 'ID-1C21D1C00BAE', 'ID-1C21D1C00BB0', 'ID-1C21D1C00BB2', 'ID-1C21D1C00BB4', 'ID-1C21D1C00BB5', 'ID-1C21D1C00BB6', 'ID-1C21D1C00BB7', 'ID-1C21D1C00BB8', 'ID-1C21D1C00BB9', 'ID-1C21D1C00BBB', 'ID-1C21D1C00BBD', 'ID-1C21D1C00BC6', 'ID-1C21D1C00BC8', 'ID-1C21D1C00BC9', 'ID-1C21D1C00BCA', 'ID-1C21D1C00BCC', 'ID-1C21D1C00BCD', 'ID-1C21D1C00BD0', 'ID-1C21D1C00BD1', 'ID-1C21D1C00BD2', 'ID-1C21D1C00BDD', 'ID-1C21D1C00BDE', 'ID-1C21D1C00BDF', 'ID-1C21D1C00BE1', 'ID-1C21D1C00BE2', 'ID-1C21D1C00BE3', 'ID-1C21D1C00BE5', 'ID-1C21D1C00BE8', 'ID-1C21D1C00BE9', 'ID-1C21D1C00BEA', 'ID-1C21D1C00BEC', 'ID-1C21D1C00BED', 'ID-1C21D1C00BEE', 'ID-1C21D1C00BEF', 'ID-1C21D1C00BF0', 'ID-1C21D1C00BF1', 'ID-1C21D1C00BF3', 'ID-1C21D1C00BF4', 'ID-1C21D1C00BF5', 'ID-1C21D1C00BF7', 'ID-1C21D1C00C19', 'ID-1C21D1C00C1B', 'ID-1C21D1C00C1C', 'ID-1C21D1C00C1E', 'ID-1C21D1C00C30', 'ID-1C21D1C00C31', 'ID-1C21D1C00C32', 'ID-1C21D1C00C33', 'ID-1C21D1C00C34', 'ID-1C21D1C00C35', 'ID-1C21D1C00C36', 'ID-1C21D1C00C37', 'ID-1C21D1C00C38', 'ID-1C21D1C00C39', 'ID-1C21D1C00C3A', 'ID-1C21D1C00C3D', 'ID-1C21D1C00C3E', 'ID-1C21D1C00C3F', 'ID-1C21D1C00C40', 'ID-1C21D1C00C44', 'ID-1C21D1C00C45', 'ID-1C21D1C00C46', 'ID-1C21D1C00C47', 'ID-1C21D1C00C50', 'ID-1C21D1C00C52', 'ID-1C21D1C00C53', 'ID-1C21D1C00C54', 'ID-1C21D1C00C56', 'ID-1C21D1C00C57', 'ID-1C21D1C00C59', 'ID-1C21D1C00C5A', 'ID-1C21D1C00C5B', 'ID-1C21D1C00C5C', 'ID-1C21D1C00C5D', 'ID-1C21D1C00C5E', 'ID-1C21D1C00C60', 'ID-1C21D1C00C61', 'ID-1C21D1C00C64', 'ID-1C21D1C00C66', 'ID-1C21D1C00C67', 'ID-1C21D1C00C70', 'ID-1C21D1C20018', 'ID-1C21D1C20036', 'ID-1C21D1C20045', 'ID-1C21D1C2004D', 'ID-1C21D1C2007A', 'ID-1C21D1C2007B', 'RTSP-0000FF0001E1', 'RTSP-0000FF0001E3', 'fed629b9-ce5c-439d-ab13-744ec6f65ff5'), style=DescriptionStyle(description_width='initial'), value='2514a72b-ead6-44a4-bafb-e4c8a684c599'), Output()), _dom_classes=('widget-interact',))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c96975e24c45e1876c5cf6c714385c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(Button(description='Prev', layout=Layout(width='50px'), style=ButtonStyle()), Button(description='Next', layout=Layout(width='50px'), style=ButtonStyle()), interactive(children=(Dropdown(description='File', layout=Layout(width='500px'), options=('alarm_mask_person_20180119033205463000_19.jpg', 'alarm_mask_person_20180119033205463000_20.jpg', 'alarm_mask_person_20180119033954599000_26.jpg', 'alarm_mask_person_20180119033954599000_28.jpg', 'alarm_mask_person_20180119034006599000_33.jpg', 'alarm_mask_person_20180119034006599000_36.jpg', 'alarm_mask_person_20180119034016995000_42.jpg', 'alarm_mask_person_20180119034016995000_44.jpg', 'alarm_mask_person_20180119034133096000_51.jpg', 'alarm_mask_person_20180119034133096000_52.jpg', 'alarm_mask_person_20180119034236175000_56.jpg', 'alarm_mask_person_20180119034253175000_60.jpg', 'alarm_mask_person_20180119034301371000_67.jpg', 'alarm_mask_person_20180119034301371000_68.jpg', 'alarm_mask_person_20180119034433359000_75.jpg', 'alarm_mask_person_20180119034433359000_76.jpg', 'alarm_mask_person_20180119034446359000_80.jpg', 'alarm_mask_person_20180119035117903000_87.jpg', 'alarm_mask_person_20180119035117903000_88.jpg', 'alarm_mask_person_20180119035135017000_95.jpg', 'alarm_mask_person_20180119035135017000_96.jpg', 'alarm_mask_person_20180119035144160000_100.jpg', 'alarm_mask_person_20180119035203536000_104.jpg', 'alarm_mask_person_20180119035227652000_108.jpg', 'alarm_mask_person_20180119035232664000_112.jpg', 'alarm_mask_person_20180119035250703000_116.jpg', 'alarm_mask_person_20180119035314816000_120.jpg', 'alarm_mask_person_20180119035319828000_124.jpg', 'alarm_mask_person_20180119035330853000_128.jpg', 'alarm_mask_person_20180119035352969000_132.jpg', 'alarm_mask_person_20180119035407197000_136.jpg', 'alarm_mask_person_20180119035508920000_140.jpg', 'alarm_mask_person_20180119035527092000_144.jpg', 'alarm_mask_person_20180119035545260000_148.jpg', 'alarm_mask_person_20180119035556420000_152.jpg', 'alarm_mask_person_20180119035620668000_156.jpg', 'alarm_mask_person_20180119035837352000_160.jpg', 'alarm_mask_person_20180119035959188000_164.jpg', 'alarm_mask_person_20180119040039736000_168.jpg', 'alarm_mask_person_20180119040150684000_172.jpg', 'alarm_mask_person_20180119040155696000_176.jpg', 'alarm_mask_person_20180119040205780000_180.jpg', 'alarm_mask_person_20180119054614622000_187.jpg', 'alarm_mask_person_20180119054614622000_188.jpg', 'alarm_mask_person_20180119161429118000_192.jpg', 'alarm_mask_person_20180119161440217000_196.jpg', 'alarm_mask_person_20180119161441217000_200.jpg', 'alarm_mask_person_20180119161515413000_204.jpg', 'alarm_mask_person_20180119161527609000_208.jpg', 'alarm_mask_person_20180119161601805000_212.jpg', 'alarm_mask_person_20180119161615862000_216.jpg', 'alarm_mask_person_20180119161632001000_220.jpg', 'alarm_mask_person_20180119161650197000_224.jpg', 'alarm_mask_person_20180119161701197000_228.jpg', 'alarm_mask_person_20180119161715254000_232.jpg', 'alarm_mask_person_20180119161722393000_236.jpg', 'alarm_mask_person_20180119161729393000_240.jpg', 'alarm_mask_person_20180119161745450000_244.jpg', 'alarm_mask_person_20180119161759502000_248.jpg', 'alarm_mask_person_20180119161804589000_252.jpg', 'alarm_mask_person_20180119161832785000_256.jpg', 'alarm_mask_person_20180119161918038000_260.jpg', 'alarm_mask_person_20180119161944173000_264.jpg', 'alarm_mask_person_20180119161944173000_268.jpg', 'alarm_mask_person_20180119162020569000_272.jpg', 'alarm_mask_person_20180119162039630000_276.jpg', 'alarm_mask_person_20180119162047765000_280.jpg', 'alarm_mask_person_20180119162108961000_284.jpg', 'alarm_mask_person_20180119162135157000_288.jpg', 'alarm_mask_person_20180119162152157000_292.jpg', 'alarm_mask_person_20180119162155157000_296.jpg', 'alarm_mask_person_20180119162211466000_300.jpg', 'alarm_mask_person_20180119162212553000_304.jpg', 'alarm_mask_person_20180119162442691000_308.jpg', 'alarm_mask_person_20180119162442691000_312.jpg', 'alarm_mask_person_20180119162445834000_316.jpg', 'alarm_mask_person_20180119162510982000_320.jpg', 'alarm_mask_person_20180119162534190000_324.jpg', 'alarm_mask_person_20180119162539193000_328.jpg', 'alarm_mask_person_20180119162541194000_332.jpg', 'alarm_mask_person_20180119163300052000_336.jpg', 'alarm_mask_person_20180119163302052000_340.jpg', 'alarm_mask_person_20180119163326248000_344.jpg', 'alarm_mask_person_20180119163333308000_348.jpg', 'alarm_mask_person_20180119163342504000_352.jpg', 'alarm_mask_person_20180119165234488000_356.jpg', 'alarm_mask_person_20180119165235493000_360.jpg', 'alarm_mask_person_20180119165253884000_364.jpg', 'alarm_mask_person_20180119165311084000_368.jpg', 'alarm_mask_person_20180119165425672000_372.jpg', 'alarm_mask_person_20180119165458868000_376.jpg', 'alarm_mask_person_20180119165509176000_380.jpg', 'alarm_mask_person_20180119165630712000_384.jpg', 'alarm_mask_person_20180119165640712000_388.jpg', 'alarm_mask_person_20180119165655908000_392.jpg', 'alarm_mask_person_20180119165705960000_399.jpg', 'alarm_mask_person_20180119165705960000_400.jpg', 'alarm_mask_person_20180119165707960000_404.jpg', 'alarm_mask_person_20180119165717048000_410.jpg', 'alarm_mask_person_20180119165717048000_412.jpg', 'alarm_mask_person_20180120045754747000_443.jpg', 'alarm_mask_person_20180120045754747000_444.jpg', 'alarm_mask_person_20180120045803947000_451.jpg', 'alarm_mask_person_20180120045803947000_452.jpg', 'alarm_mask_person_20180120045849539000_456.jpg', 'alarm_mask_person_20180120045852539000_460.jpg', 'alarm_mask_person_20180120045914935000_464.jpg', 'alarm_mask_person_20180120050119919000_468.jpg', 'alarm_mask_person_20180120050124981000_472.jpg', 'alarm_mask_person_20180120050133175000_476.jpg', 'alarm_mask_person_20180120050140176000_480.jpg', 'alarm_mask_person_20180120050201716000_484.jpg', 'alarm_mask_person_20180120050313503000_491.jpg', 'alarm_mask_person_20180120050313503000_492.jpg', 'alarm_mask_person_20180120050346899000_499.jpg', 'alarm_mask_person_20180120050346899000_500.jpg', 'alarm_mask_person_20180120050416552000_504.jpg', 'alarm_mask_person_20180120050552479000_508.jpg', 'alarm_mask_person_20180120050711528000_512.jpg', 'alarm_mask_person_20180120050727867000_516.jpg', 'alarm_mask_person_20180120050803372000_520.jpg', 'alarm_mask_person_20180120050850915000_524.jpg', 'alarm_mask_person_20180120050920251000_528.jpg', 'alarm_mask_person_20180120051034039000_535.jpg', 'alarm_mask_person_20180120051034039000_536.jpg', 'alarm_mask_person_20180120051344811000_540.jpg', 'alarm_mask_person_20180120051420007000_544.jpg', 'alarm_mask_person_20180120051439603000_548.jpg', 'alarm_mask_person_20180120051503712000_552.jpg', 'alarm_mask_person_20180120051512799000_556.jpg', 'alarm_mask_person_20180120053645615000_560.jpg', 'alarm_mask_person_20180120053646615000_564.jpg', 'alarm_mask_person_20180120055623251000_571.jpg', 'alarm_mask_person_20180120055623251000_572.jpg', 'alarm_mask_person_20180120055630308000_576.jpg', 'alarm_mask_person_20180120055809235000_580.jpg', 'alarm_mask_person_20180120055845631000_584.jpg', 'alarm_mask_person_20180120055902827000_588.jpg', 'alarm_mask_person_20180120055931023000_592.jpg', 'alarm_mask_person_20180120060136067000_596.jpg', 'alarm_mask_person_20180120060218399000_600.jpg', 'alarm_mask_person_20180120060443092000_604.jpg', 'alarm_mask_person_20180120060448179000_608.jpg', 'alarm_mask_person_20180120060456179000_612.jpg', 'alarm_mask_person_20180120060505288000_616.jpg', 'alarm_mask_person_20180120060520775000_620.jpg', 'alarm_mask_person_20180120060613367000_624.jpg', 'alarm_mask_person_20180120060703159000_628.jpg', 'alarm_mask_person_20180120060735355000_632.jpg', 'alarm_mask_person_20180120060737355000_636.jpg', 'alarm_mask_person_20180120060744463000_643.jpg', 'alarm_mask_person_20180120060744463000_644.jpg', 'alarm_mask_person_20180120064504467000_648.jpg', 'alarm_mask_person_20180120064505515000_652.jpg', 'alarm_mask_person_20180120064649303000_656.jpg', 'alarm_mask_person_20180120064743586000_663.jpg', 'alarm_mask_person_20180120064743586000_664.jpg', 'alarm_mask_person_20180120064748695000_668.jpg', 'alarm_mask_person_20180120064754782000_672.jpg', 'alarm_mask_person_20180120164343690000_728.jpg', 'alarm_mask_person_20180120165912689000_884.jpg', 'alarm_mask_person_20180121065039218000_904.jpg', 'alarm_mask_person_20180121065041222000_908.jpg', 'alarm_mask_person_20180121114801121000_916.jpg', 'alarm_mask_person_20180122033908670000_923.jpg', 'alarm_mask_person_20180122033908670000_924.jpg', 'alarm_mask_person_20180122033925085000_928.jpg', 'alarm_mask_person_20180122034059273000_932.jpg', 'alarm_mask_person_20180122034254518000_936.jpg', 'alarm_mask_person_20180122034312914000_940.jpg', 'alarm_mask_person_20180122034344359000_944.jpg', 'alarm_mask_person_20180122034421959000_948.jpg', 'alarm_mask_person_20180122034544894000_952.jpg', 'alarm_mask_person_20180122034615289000_956.jpg', 'alarm_mask_person_20180122034621425000_960.jpg', 'alarm_mask_person_20180122034635485000_964.jpg', 'alarm_mask_person_20180122034646687000_968.jpg', 'alarm_mask_person_20180122034651821000_972.jpg', 'alarm_mask_person_20180122034701934000_976.jpg', 'alarm_mask_person_20180122034738217000_980.jpg', 'alarm_mask_person_20180122035922117000_987.jpg', 'alarm_mask_person_20180122035922117000_988.jpg', 'alarm_mask_person_20180122035928226000_992.jpg', 'alarm_mask_person_20180122035935426000_1000.jpg', 'alarm_mask_person_20180122035935426000_999.jpg', 'alarm_mask_person_20180122035957713000_1004.jpg', 'alarm_mask_person_20180122040007770000_1011.jpg', 'alarm_mask_person_20180122040007770000_1012.jpg', 'alarm_mask_person_20180122040451069000_1019.jpg', 'alarm_mask_person_20180122040451069000_1020.jpg', 'alarm_mask_person_20180122040504069000_1024.jpg', 'alarm_mask_person_20180122041855354000_1028.jpg', 'alarm_mask_person_20180122041855354000_1032.jpg', 'alarm_mask_person_20180122041901478000_1036.jpg', 'alarm_mask_person_20180122041903482000_1040.jpg', 'alarm_mask_person_20180122042003206000_1044.jpg', 'alarm_mask_person_20180122042400498000_1048.jpg', 'alarm_mask_person_20180122042418534000_1052.jpg', 'alarm_mask_person_20180122043105085000_1056.jpg', 'alarm_mask_person_20180122043116179000_1060.jpg', 'alarm_mask_person_20180122043145321000_1064.jpg', 'alarm_mask_person_20180122114004478000_1068.jpg', 'alarm_mask_person_20180122121140199000_1072.jpg', 'alarm_mask_person_20180122153510120000_1076.jpg', 'alarm_mask_person_20180123033100459000_1092.jpg', 'alarm_mask_person_20180123033101459000_1096.jpg', 'alarm_mask_person_20180123033124998000_1100.jpg', 'alarm_mask_person_20180123033215499000_1104.jpg', 'alarm_mask_person_20180123033653811000_1108.jpg', 'alarm_mask_person_20180123034051718000_1115.jpg', 'alarm_mask_person_20180123034051718000_1116.jpg', 'alarm_mask_person_20180123034134171000_1120.jpg', 'alarm_mask_person_20180123034211567000_1124.jpg', 'alarm_mask_person_20180123034223815000_1128.jpg', 'alarm_mask_person_20180123034236963000_1132.jpg', 'alarm_mask_person_20180123034304298000_1136.jpg', 'alarm_mask_person_20180123034322407000_1140.jpg', 'alarm_mask_person_20180123034332494000_1144.jpg', 'alarm_mask_person_20180123034341603000_1148.jpg', 'alarm_mask_person_20180123034347603000_1152.jpg', 'alarm_mask_person_20180123034354690000_1156.jpg', 'alarm_mask_person_20180123034427887000_1163.jpg', 'alarm_mask_person_20180123034427887000_1164.jpg', 'alarm_mask_person_20180123034453283000_1168.jpg', 'alarm_mask_person_20180123034458344000_1172.jpg', 'alarm_mask_person_20180123034508596000_1176.jpg', 'alarm_mask_person_20180123034614583000_1180.jpg', 'alarm_mask_person_20180123034616670000_1184.jpg', 'alarm_mask_person_20180123034619870000_1188.jpg', 'alarm_mask_person_20180123034640979000_1192.jpg', 'alarm_mask_person_20180123034653327000_1196.jpg', 'alarm_mask_person_20180123034700375000_1200.jpg', 'alarm_mask_person_20180123034708523000_1204.jpg', 'alarm_mask_person_20180123034718663000_1208.jpg', 'alarm_mask_person_20180123034720724000_1212.jpg', 'alarm_mask_person_20180123034739322000_1216.jpg', 'alarm_mask_person_20180123034740371000_1220.jpg', 'alarm_mask_person_20180123035003438000_1227.jpg', 'alarm_mask_person_20180123035003438000_1228.jpg', 'alarm_mask_person_20180123045938154000_1232.jpg', 'alarm_mask_person_20180123045941242000_1236.jpg', 'alarm_mask_person_20180123050011498000_1240.jpg', 'alarm_mask_person_20180123161224481000_4.jpg', 'alarm_mask_person_20180123161228489000_11.jpg', 'alarm_mask_person_20180123161228489000_12.jpg', 'alarm_mask_person_20180124033035414000_4.jpg', 'alarm_mask_person_20180124033042414000_8.jpg', 'alarm_mask_person_20180124033048471000_12.jpg', 'alarm_mask_person_20180124033234598000_16.jpg', 'alarm_mask_person_20180124033234598000_20.jpg', 'alarm_mask_person_20180124033327990000_24.jpg', 'alarm_mask_person_20180124033345186000_28.jpg', 'alarm_mask_person_20180124033510235000_32.jpg', 'alarm_mask_person_20180124033535570000_36.jpg', 'alarm_mask_person_20180124033548570000_40.jpg', 'alarm_mask_person_20180124033619766000_44.jpg', 'alarm_mask_person_20180124033636962000_48.jpg'), style=DescriptionStyle(description_width='initial'), value='alarm_mask_person_20180119033205463000_19.jpg'), Output()), _dom_classes=('widget-interact',))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.HBox([buttonCamPrev,buttonCamNext,i]))\n",
    "display(widgets.HBox([buttonFilePrev,buttonFileNext,j]))\n",
    "# print(' Global fraction of FPs removed: ', GlobalFPsremoved,'\\n Global fraction of TPs removed: ', GlobalTPsremoved,\n",
    "#        '\\n Mean Fraction of FPs removed (per camera): ', MeanFPsremoved,'\\n Mean Fraction of TPs removed (per camera): ',\n",
    "#        MeanTPsremoved, '\\n Cameras using filter (others do not have enough FPs or do not have enough data): ', len(Infos),\n",
    "#       ' out of ', len(GroupID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alarm_mask_person_20180119071307354000_112.jpg 1 -1 False\n",
      "alarm_mask_person_20180119071323354000_116.jpg 1 -1 False\n",
      "alarm_mask_person_20180119091624149000_120.jpg 1 -1 False\n",
      "alarm_mask_person_20180119093706629000_124.jpg 1 -1 False\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(GroupID.get_group(CamID.value))):\n",
    "    line = GroupID.get_group(CamID.value).iloc[i,] \n",
    "    x = line.Centroidsx\n",
    "    y = line.Centroidsy\n",
    "    a = line.area\n",
    "    col = [255,0,0]\n",
    "    if Classifier([x,y,a]) == '1': col = [0,255,0]\n",
    "    print(GroupID.get_group(CamID.value).iloc[i,].file ,Classifier([x,y,a]),\n",
    "          GroupID.get_group(CamID.value).iloc[i,].label,\n",
    "          Classifier([x,y,a]) == GroupID.get_group(CamID.value).iloc[i,].label,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 255, 0]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GroupID.get_group(CamID.value).file == FileName.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93.30434782608695, 101.76086956521739, 108)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "f(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
